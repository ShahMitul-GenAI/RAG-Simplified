{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3abbe95a-9384-427b-9921-f81c4bb05f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import Tool\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain.schema.document import Document\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.agents.initialize import initialize_agent\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.utilities import WikipediaAPIWrapper \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a485ef8d-26a9-49b6-b947-371edaf7ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading API keys from env\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6fb9e76a-ca4a-4b7d-9412-160816ae149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model and defining embedding\n",
    "llm = ChatOpenAI(temperature=0, model='gpt-3.5-turbo')\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "864ded0a-b50d-4b35-803c-2d3e65b24339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up info retreival from Wikipedia pages (1st knowledge source)\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "prompt = \"When did WHO declare an end of COVID-19 emergency?\"\n",
    "wiki_output = wikipedia.run(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c356c153-042e-4f5e-83ea-5994e93e9326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fragmegting the document content to fit in the number of token limitations\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 50)\n",
    "new_docs = [Document(page_content=sent) for sent in wiki_output.split('\\n')]\n",
    "\n",
    "# splitted_output = text_splitter.split_documents(new_doc)\n",
    "data_set = DocArrayInMemorySearch.from_documents(new_docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4a76e54c-0e19-4ea8-9e16-e5b06219e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retreiving the llm response using user query\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm =llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever = data_set.as_retriever(),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d56a363a-489e-4e09-951d-47ba280d8951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The World Health Organization (WHO) ended the Public Health Emergency of International Concern (PHEIC) for COVID-19 on 5 May 2023.\n"
     ]
    }
   ],
   "source": [
    "print(qa(prompt)['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d3528185-79d6-4eb5-bae4-e9f8e5e34e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading research paper from web source (2nd knoledge source)\n",
    "loader = PyPDFLoader(\"./2312.10997v5.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# fragmegting the document content to fit in the number of token limitations\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 50)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# load the \n",
    "data_set = DocArrayInMemorySearch.from_documents(documents=splits, embedding=embedings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cfa09c47-bb9b-41da-946d-a5cc8f722e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retreiving the llm response using user query\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm =llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever = data_set.as_retriever(),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "16d711cc-89cc-410d-848c-799e0cefb58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "'Advanced RAG' for Large Language Models refers to the development trajectory of Retrieval-Augmented Generation (RAG) in the era of large models. Initially, RAG focused on enhancing language models by incorporating additional knowledge through Pre-Training Models (PTM). The stages of involving RAG mainly include pre-training, fine-tuning, and inference. Researchers have been exploring ways to enhance language models by leveraging the powerful in-context learning abilities of large language models and integrating more with the fine-tuning of these models. Advanced RAG involves the integration of state-of-the-art technologies in each of these critical components to enhance the performance of RAG systems.\n"
     ]
    }
   ],
   "source": [
    "# get query from U/I now\n",
    "prompt = \"What is 'Advanced RAG' for Large Language Models?\"\n",
    "result = qa(prompt)\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "19d2d9fb-481d-433f-bb23-a384c2f21077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The World Health Organization (WHO) declared an end to the COVID-19 emergency on 5 May 2023.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "'Naive RAG' for Large Language Models is a method that relies directly on the user's original query for retrieval, but faces challenges with imprecise queries and language complexity.\n"
     ]
    }
   ],
   "source": [
    "# combining two RAG knoledge sources together for better performance\n",
    "from langchain.agents.initialize import initialize_agent\n",
    "wiki_tool = Tool(\n",
    "    name = \"wikipedia\",\n",
    "    func = wikipedia.run,\n",
    "    description = \"A useful tool to search internet for the requested information\",\n",
    ")\n",
    "\n",
    "docsearch_tool = Tool(\n",
    "    name = \"docsearch\",\n",
    "    func = qa.run,\n",
    "    description = \"A tool to search information from the pool of documents\",\n",
    ")\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools = [wiki_tool, docsearch_tool],\n",
    "    llm = llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = False,\n",
    "    handle_pasring_errors = True,\n",
    ")\n",
    "print(agent.invoke(\"When did WHO declares an end of COVID-19 emergency?\")['output']) \n",
    "print(agent.invoke(\"What is 'Naive RAG' for Large Language Models?\")['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a99e5e-7143-45c1-9427-6a81a17fcb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the program termination indicator\n",
    "fend = open('./notifications/PROG EXIT.txt','wb')\n",
    "pickle.dump(123, fend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
